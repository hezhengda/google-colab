{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch for deep learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyYUBsoRK4BtHNlw2oPPEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hezhengda/google-colab/blob/main/Pytorch_for_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN7SxhmtMGg7"
      },
      "source": [
        "# Basics of Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ8Tl1T8MR2y"
      },
      "source": [
        "**Traditional programming**: input + algorithm --> output\n",
        "\n",
        "**New paradigm**: input + output --> algorithm (if we cannot write the algorithm and there are many outliers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-48c_Po9Mxvc"
      },
      "source": [
        "## Pytorch jargons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h-1AOnZND79"
      },
      "source": [
        "**Tensor**: A tensor can be a number, a vector, a matrix or any n-dimensional array (so it is just another name for n-dimensional array [NDA])\n",
        "\n",
        "The difference between tensor and n-dimensional array:\n",
        "* The size of tensor should not change\n",
        "* When you try to do a tensor operation, do it in the tensor type because it is implemented in C++ (which means really fast), but if you do it in python, then it is really slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTf1E8KVN4jA"
      },
      "source": [
        "# import pytorch\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNznCmfNN7bj",
        "outputId": "15e1643f-6051-44c9-de6e-b79e16edadcc"
      },
      "source": [
        "# set a number\n",
        "a = torch.tensor(4.0)\n",
        "print(a,'|', a.dtype,'|', a.shape)\n",
        "\n",
        "# set a vector\n",
        "b = torch.tensor([1, 2, 3, 4])\n",
        "print(b,'|',  b.dtype,'|',  b.shape)\n",
        "\n",
        "# set a matrix\n",
        "c = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "print(c,'|',  c.dtype,'|',  c.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.) | torch.float32 | torch.Size([])\n",
            "tensor([1, 2, 3, 4]) | torch.int64 | torch.Size([4])\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) | torch.int64 | torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Ifj3KTPR18"
      },
      "source": [
        "## Create tensors\n",
        "\n",
        "The `requires_grad` is important to understand. This is used for improving the efficiency of your code, because when your code gets more complex, the time on calculating gradients becomes larger, so we need to find a way to tell the program which gradient we need and which we needn't, if we set `requires_grad=True` to a variable, that means we want to have its derivative. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZeM7XnLOEVx"
      },
      "source": [
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True) # what's the meaning of this \"requires_grad\"?\n",
        "b = torch.tensor(5., requires_grad=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_0ltr_xP5V7",
        "outputId": "87f040be-7e7e-41ed-fa0c-ac2a8045d51a"
      },
      "source": [
        "# Arithmatic operations\n",
        "y = w * x + b\n",
        "print('{}, {}'.format(y, y.requires_grad))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.0, True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEw825W2P9GN"
      },
      "source": [
        "# compute derivatives --> for gradient descent\n",
        "y.backward()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba5Eqi03QPRI",
        "outputId": "8f80d2d1-f6d3-4d2f-9fdc-6cd1fe3ee585"
      },
      "source": [
        "# display the gradients\n",
        "print('dy/dx:', x.grad) # output None because x doesn't have \"requires_grad\"\n",
        "print('dy/dw:', w.grad) # 3 because x = 3\n",
        "print('dy/db:', b.grad) # 1 because the coefficient of b is 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv1YAHxkTjES"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**Problems**\n",
        "Now let's try to solve some questions:\n",
        "\n",
        "1. What if in $y=w\\times x+b$, the `w`, `x` and `b` are all 1-dimensional array? What about two-dimensional array? What will `w.grad` looks like?\n",
        "\n",
        "  * When the tensor is 1D tensor, there is no gradient ?\n",
        "\n",
        "2. What if we have the **chain role**, which means: $y = w\\times x + b$, $w = m\\times p + q$? What will happen if we want to calcualte `p.grad`?\n",
        "\n",
        "  * If you make sure that you have the leaf node, then the gradient is correct, but if not, then you need to use other settings, e.g. `retain_grad()` on the non-leaf tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFUa5H7nUrIv",
        "outputId": "b186112e-90d4-46ee-9ee6-bc99381c6992"
      },
      "source": [
        "# Problem 1 - tensor operation is by element\n",
        "x = torch.tensor([1.0, 2.0])\n",
        "w = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "b = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y = w * x + b\n",
        "print(y)\n",
        "print('dy/dw:', w.grad)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 6.], grad_fn=<AddBackward0>)\n",
            "dy/dw: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyJlx5vVV5n8",
        "outputId": "18916772-d840-4a62-97a5-9933612704be"
      },
      "source": [
        "# Problem 2 - chain role \n",
        "x = torch.tensor(1.0)\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(5.0, requires_grad=True)\n",
        "\n",
        "c = w + b \n",
        "c.retain_grad() # since c is a non-leaf node, then you need to use \n",
        "y = c * w * x + b\n",
        "\n",
        "# calculate gradient\n",
        "y.backward()\n",
        "print('dy/dw: ', w.grad)\n",
        "print('dy/dc: ', c.grad)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dw:  tensor(9.)\n",
            "dy/dc:  tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TzrHXY3Rd3c"
      },
      "source": [
        "## Interoperability with Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZhCEnllR6l2"
      },
      "source": [
        "If you want to change numpy array to tensor, you need to use `torch.from_numpy(array)`.\n",
        "\n",
        "Convert from pytorch tensor to numpy array: `y.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHq6TSAQmzE"
      },
      "source": [
        "# numpy is written in C++, which means this is very efficient\n",
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUFOeD63RmCw",
        "outputId": "8075281f-882a-464a-c228-3858b13a803e"
      },
      "source": [
        "x = np.array([[1, 2],[3, 4]])\n",
        "y = torch.from_numpy(x)\n",
        "print(y, y.dtype)\n",
        "z = y.numpy()\n",
        "print(z, z.dtype)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) torch.int64\n",
            "[[1 2]\n",
            " [3 4]] int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ1PmuQIYKgi"
      },
      "source": [
        "# Linear Regression of PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpA-ShfjYUFC"
      },
      "source": [
        "Linear Regression means that we want to rationalize the data by using a linear model: $y = wx+b$. (w: weights, b: bias) We know all the $(x,y)$, now we want to find the optimal coefficient $(m,b)$. Notice that in here, `w` could be a matrix and `b` could also be a vector when `x` and `y` are vectors.\n",
        "\n",
        "This is a really simple assumption and usually it is the first step of our modeling process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaGxWNPwaQr9"
      },
      "source": [
        "Our first problem is to predict the yield of apple and orange by giving a certain temperature, rainfall and humidity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMZm1yUvf9C1"
      },
      "source": [
        "## Set inputs and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcATp1lSqzK"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPY5f6yxaos3"
      },
      "source": [
        "# Targets (yield_apples, yield_oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlMluBfa4ka"
      },
      "source": [
        "The reason why we seperate the input variables and target variables is because we need to treat them differently in our program. Also we've created numpy arrays, because this is typically how you would work with training data: read some CSV files as numpy arrays, do some processing, and then convert them to Pytorch tensors to do further training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnTLuX6jazeE"
      },
      "source": [
        "# convert numpy array for torch tensors\n",
        "inputs_torch = torch.from_numpy(inputs)\n",
        "targets_torch = torch.from_numpy(targets)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-tqZKydbUf6",
        "outputId": "d9528d10-12a4-4cd8-979b-7749b7cb23c7"
      },
      "source": [
        "# start the value of weight and bias from a random value\n",
        "# since we have 2 targets and 3 inputs, then our weight should be a 2x3 matrix\n",
        "# our bias should have same size as our targets\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(1, 2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3066,  0.9426, -1.5872],\n",
            "        [-1.2522,  1.0184, -1.1143]], requires_grad=True)\n",
            "tensor([[0.3716, 0.0434]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InOucMrTcNiB"
      },
      "source": [
        "When our weight is a matrix, then our linear regression can be written as:\n",
        "$$y = x \\cdot w^T + b$$\n",
        "\n",
        "The size of our weight matrix is related to the number of features and the number of outputs.\n",
        "\n",
        "**Make sure that the dimension of your matrix is correct! Really important!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQQEfg0sgUd-"
      },
      "source": [
        "## Build our model\n",
        "\n",
        "In this case it is a linear regression model, but in the future, the model can be really complex (e.g. A neural network model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TTNWlHcbofF"
      },
      "source": [
        "# define the model\n",
        "def model(x):\n",
        "  return x @ w.t() + b # @ means matrix multiplication"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkyB357FctO_",
        "outputId": "655b935f-cbb0-4b7f-ebc3-8f81dc736deb"
      },
      "source": [
        "# predictions of our model \n",
        "preds = model(inputs_torch)\n",
        "print(preds) # really, really bad ... right now ..."
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[100.3761,  17.6190],\n",
            "        [133.1410,  10.2199],\n",
            "        [ 80.8693, -55.7864],\n",
            "        [156.0216, 105.1184],\n",
            "        [101.3740, -43.1640]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm61a70DdXEZ",
        "outputId": "e5dc2910-cadb-4f01-9ed1-10e8ffa8add1"
      },
      "source": [
        "print(targets_torch)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvibYOtWgd9o"
      },
      "source": [
        "## Calculate the loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrWFiEpMfRLz"
      },
      "source": [
        "The **mean-square error** can be defined as:\n",
        "\n",
        "$$mse=\\frac{1}{N}\\sum_{i=1}^N(t_1^i-t_2^i)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXxoXuF9ee2z"
      },
      "source": [
        "# define the mean-square error\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff*diff)/diff.numel() # diff*diff: element-wise multiplication; diff.numel() number of elements in diff"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jAhXRlegps-"
      },
      "source": [
        "## Calculate the gradient --> Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K0Olkrjg2N7"
      },
      "source": [
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(1, 2, requires_grad=True)\n",
        "threshold = 10\n",
        "lr = 1e-5 # learning_rate\n",
        "ind = 0 #\n",
        "preds = model(inputs_torch)\n",
        "loss = mse(preds, targets_torch)\n",
        "print(loss)\n",
        "while loss > threshold:\n",
        "    new_preds = model(inputs_torch)\n",
        "    loss = mse(new_preds, targets_torch)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad\n",
        "        b -= lr * b.grad\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "    ind += 1\n",
        "    print('Epoch {} ... loss = {}'.format(ind, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjdbNE2bwrDn",
        "outputId": "78db523d-f6f9-49b5-90c3-078606f27ad1"
      },
      "source": [
        "preds = model(inputs_torch)\n",
        "print(preds)\n",
        "print(targets_torch)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 58.2112,  69.5565],\n",
            "        [ 81.6339, 100.3739],\n",
            "        [118.3174, 134.8474],\n",
            "        [ 26.1825,  31.0243],\n",
            "        [ 98.1191, 122.4509]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86DqZcj8v-nf"
      },
      "source": [
        "In here I need to say: in pytorch, `a = a - 1` is not the same as `a -= 1`.\n",
        "\n",
        "* `a = a - 1` means first we evaluate `a-1`, then we create another tensor `a`, which has different reference number \n",
        "\n",
        "* `a -= 1` means we only evaluate `a-1`, but the reference for `a` is the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHp4QPwKtRlG",
        "outputId": "63eabb25-03c9-4a3b-cf9d-846599f4bfd0"
      },
      "source": [
        "a = torch.tensor([1, 2])\n",
        "print('original id = {}'.format(id(a)))\n",
        "b = torch.tensor([2, 2])\n",
        "a -= b\n",
        "print('After a = a - b, id = {}'.format(id(a)))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original id = 139940533485432\n",
            "After a = a - b, id = 139940533485432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl3KGIFMx5AT"
      },
      "source": [
        "## Use pytorch built-in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mMzf5S3yVeb"
      },
      "source": [
        "import torch.nn as nn \n",
        "# nn means neural network"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWEuui7ax4Ky"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNZF152btyOG"
      },
      "source": [
        "# dataset and dataloader (batching)\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# define our dataset \n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "\n",
        "# dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# define batch size \n",
        "batch_size = 10\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufkn4nQ0yyzV",
        "outputId": "b362add0-cf08-46fb-f26f-15a67cd25641"
      },
      "source": [
        "# look at 1 batch\n",
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 87., 134.,  58.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [103.,  43.,  36.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [ 68.,  96.,  71.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[119., 133.],\n",
            "        [ 56.,  70.],\n",
            "        [ 57.,  69.],\n",
            "        [ 21.,  38.],\n",
            "        [ 80., 102.],\n",
            "        [ 20.,  38.],\n",
            "        [118., 134.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf_iaTAVzSBi",
        "outputId": "819e0627-0363-4a89-c1f8-06b5d5620bde"
      },
      "source": [
        "# define model\n",
        "model = nn.Linear(3, 2) # 3 is the number of your features, 2 is the number of your outputs\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0298,  0.4024, -0.1152],\n",
            "        [ 0.5231, -0.2843, -0.1735]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1466, 0.4071], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnN3msG6zouY",
        "outputId": "13b35dc9-d295-4873-850c-028cd9542ce2"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0298,  0.4024, -0.1152],\n",
              "         [ 0.5231, -0.2843, -0.1735]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1466, 0.4071], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf4IrLNszs1H",
        "outputId": "40a8a6cf-80e6-4bf8-9266-b640efe205d4"
      },
      "source": [
        "# make predictions\n",
        "preds = model(inputs_torch)\n",
        "print(preds)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[19.9765, 12.0850],\n",
            "        [25.4707, 11.8874],\n",
            "        [44.7912, -2.2405],\n",
            "        [10.1458, 35.1170],\n",
            "        [28.6545, -2.9349]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33klDScoz3pA",
        "outputId": "b9fd4d48-6e47-4b80-ac67-cb840b92e425"
      },
      "source": [
        "# define loss function \n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_fn = F.mse_loss\n",
        "\n",
        "loss = loss_fn(model(inputs_torch), targets_torch)\n",
        "print(loss)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6001.2764, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN4358eD0YqZ"
      },
      "source": [
        "# define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5) # lr means learning-rate"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfUBSI5Z0mpN"
      },
      "source": [
        "# train the model\n",
        "# utility function to train the model \n",
        "def fit(num_epochs, train_dl, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb, yb in train_dl:\n",
        "            # 1. Generate prediction\n",
        "            preds = model(xb)\n",
        "\n",
        "            # 2. Calculate the loss \n",
        "            loss = loss_fn(preds, yb)\n",
        "\n",
        "            # 3. Compute gradients \n",
        "            loss.backward()\n",
        "\n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "\n",
        "            # 5. Reset the gradients to zero \n",
        "            opt.zero_grad() \n",
        "\n",
        "        if (epoch+1)%10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss))\n",
        "             "
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnrG4wQU1lEq",
        "outputId": "44279dd6-f7d6-4f43-bc34-98b303ea503a"
      },
      "source": [
        "fit(100, train_dl, model, loss_fn, opt)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 42.0496\n",
            "Epoch [20/100], Loss: 44.0107\n",
            "Epoch [30/100], Loss: 80.4472\n",
            "Epoch [40/100], Loss: 71.6844\n",
            "Epoch [50/100], Loss: 45.9663\n",
            "Epoch [60/100], Loss: 40.9093\n",
            "Epoch [70/100], Loss: 49.8164\n",
            "Epoch [80/100], Loss: 39.4097\n",
            "Epoch [90/100], Loss: 34.3259\n",
            "Epoch [100/100], Loss: 18.9639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYxaRa1K1pzX",
        "outputId": "7ae7649b-c5d8-431b-f912-eeb6051918f4"
      },
      "source": [
        "preds = model(inputs)\n",
        "print(preds)\n",
        "print(targets)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 57.6456,  71.5131],\n",
            "        [ 79.2267,  97.5071],\n",
            "        [123.2662, 137.0268],\n",
            "        [ 24.5356,  44.1636],\n",
            "        [ 94.8529, 109.6299],\n",
            "        [ 56.3971,  70.5016],\n",
            "        [ 78.5486,  97.0258],\n",
            "        [123.2827, 137.3443],\n",
            "        [ 25.7841,  45.1751],\n",
            "        [ 95.4234, 110.1600],\n",
            "        [ 56.9675,  71.0317],\n",
            "        [ 77.9782,  96.4957],\n",
            "        [123.9443, 137.5082],\n",
            "        [ 23.9652,  43.6335],\n",
            "        [ 96.1015, 110.6414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAnKS6l2RiI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}