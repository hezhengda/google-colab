{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch for deep learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAH1PX0ql+Bji/AhOdsRn+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13eabfacef7f4472ab72a1867d760829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98d526ad8cac4592af6824f55ae76a28",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a90271fb4e2e4f44995b0bfd49be56d1",
              "IPY_MODEL_860da238b2e84a0fa09c6905d453c89a"
            ]
          }
        },
        "98d526ad8cac4592af6824f55ae76a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a90271fb4e2e4f44995b0bfd49be56d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf8bb4259d0341d1a0a3a209f1773080",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_917b17c9d11445c1ab916142c5a0621a"
          }
        },
        "860da238b2e84a0fa09c6905d453c89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bba5431464184751a4a009d90d70ab4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 3048462.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a251c2daa3af4172ac7931beaa65452f"
          }
        },
        "bf8bb4259d0341d1a0a3a209f1773080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "917b17c9d11445c1ab916142c5a0621a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bba5431464184751a4a009d90d70ab4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a251c2daa3af4172ac7931beaa65452f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e97ac7b2bb694f4997bebb92ddf37dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_456477b388094258b56c8ecef3ddefec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a9e38bd200f4a0ab76c2bd8c1e3f0f2",
              "IPY_MODEL_ca07778e5d5645588e7d6e42de6b2e6b"
            ]
          }
        },
        "456477b388094258b56c8ecef3ddefec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a9e38bd200f4a0ab76c2bd8c1e3f0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a47cf0dffdf94706a902be093fc5bab0",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbd25e5db02e46e09260fd0851c8709d"
          }
        },
        "ca07778e5d5645588e7d6e42de6b2e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae6f17392a9548c2a082d4392ccfae15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9ffb1d7ee33408283ff9041b9da48f9"
          }
        },
        "a47cf0dffdf94706a902be093fc5bab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbd25e5db02e46e09260fd0851c8709d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae6f17392a9548c2a082d4392ccfae15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9ffb1d7ee33408283ff9041b9da48f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "199b414d84a54ff0a78ba98e52236c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b370630541f4ebc94baebd797deeff7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42fb6fd0147f4aa49d2610a6b73f1c2f",
              "IPY_MODEL_200b67cb9de6430280487a5a47f9ec4d"
            ]
          }
        },
        "5b370630541f4ebc94baebd797deeff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42fb6fd0147f4aa49d2610a6b73f1c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_342b599c20ad404da4a33bd6c3b1fa72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9427f74c92fb46d7a790ac71064b01eb"
          }
        },
        "200b67cb9de6430280487a5a47f9ec4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c40e9bc396df49d79e71c779532c7d87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:15&lt;00:00, 578944.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebe8a51e57774d70a2cbe56041f202df"
          }
        },
        "342b599c20ad404da4a33bd6c3b1fa72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9427f74c92fb46d7a790ac71064b01eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c40e9bc396df49d79e71c779532c7d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebe8a51e57774d70a2cbe56041f202df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1e3b4669da446e28f5bd8273d7b395b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfaa9223770c4382854ea2f529705071",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e4ca7e78a9e411b88aae61d5468c98c",
              "IPY_MODEL_a15417c450b2400b8a360c48b2f58f7e"
            ]
          }
        },
        "cfaa9223770c4382854ea2f529705071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e4ca7e78a9e411b88aae61d5468c98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e62772c132504383b93236c67d350de2",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bf29cbf56cb4974bf171d463c37bd37"
          }
        },
        "a15417c450b2400b8a360c48b2f58f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9506ac17d4ea4b7ea72028a149663d9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3368b7a7476e4993ad4caacbeeebbb3d"
          }
        },
        "e62772c132504383b93236c67d350de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bf29cbf56cb4974bf171d463c37bd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9506ac17d4ea4b7ea72028a149663d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3368b7a7476e4993ad4caacbeeebbb3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hezhengda/google-colab/blob/main/Pytorch_for_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN7SxhmtMGg7"
      },
      "source": [
        "# Basics of Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ8Tl1T8MR2y"
      },
      "source": [
        "**Traditional programming**: input + algorithm --> output\n",
        "\n",
        "**New paradigm**: input + output --> algorithm (if we cannot write the algorithm and there are many outliers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-48c_Po9Mxvc"
      },
      "source": [
        "## Pytorch jargons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h-1AOnZND79"
      },
      "source": [
        "**Tensor**: A tensor can be a number, a vector, a matrix or any n-dimensional array (so it is just another name for n-dimensional array [NDA])\n",
        "\n",
        "The difference between tensor and n-dimensional array:\n",
        "* The size of tensor should not change\n",
        "* When you try to do a tensor operation, do it in the tensor type because it is implemented in C++ (which means really fast), but if you do it in python, then it is really slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTf1E8KVN4jA"
      },
      "source": [
        "# import pytorch\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNznCmfNN7bj",
        "outputId": "15e1643f-6051-44c9-de6e-b79e16edadcc"
      },
      "source": [
        "# set a number\n",
        "a = torch.tensor(4.0)\n",
        "print(a,'|', a.dtype,'|', a.shape)\n",
        "\n",
        "# set a vector\n",
        "b = torch.tensor([1, 2, 3, 4])\n",
        "print(b,'|',  b.dtype,'|',  b.shape)\n",
        "\n",
        "# set a matrix\n",
        "c = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "print(c,'|',  c.dtype,'|',  c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.) | torch.float32 | torch.Size([])\n",
            "tensor([1, 2, 3, 4]) | torch.int64 | torch.Size([4])\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]]) | torch.int64 | torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Ifj3KTPR18"
      },
      "source": [
        "## Create tensors\n",
        "\n",
        "The `requires_grad` is important to understand. This is used for improving the efficiency of your code, because when your code gets more complex, the time on calculating gradients becomes larger, so we need to find a way to tell the program which gradient we need and which we needn't, if we set `requires_grad=True` to a variable, that means we want to have its derivative. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZeM7XnLOEVx"
      },
      "source": [
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True) # what's the meaning of this \"requires_grad\"?\n",
        "b = torch.tensor(5., requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_0ltr_xP5V7",
        "outputId": "87f040be-7e7e-41ed-fa0c-ac2a8045d51a"
      },
      "source": [
        "# Arithmatic operations\n",
        "y = w * x + b\n",
        "print('{}, {}'.format(y, y.requires_grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.0, True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEw825W2P9GN"
      },
      "source": [
        "# compute derivatives --> for gradient descent\n",
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba5Eqi03QPRI",
        "outputId": "8f80d2d1-f6d3-4d2f-9fdc-6cd1fe3ee585"
      },
      "source": [
        "# display the gradients\n",
        "print('dy/dx:', x.grad) # output None because x doesn't have \"requires_grad\"\n",
        "print('dy/dw:', w.grad) # 3 because x = 3\n",
        "print('dy/db:', b.grad) # 1 because the coefficient of b is 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv1YAHxkTjES"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**Problems**\n",
        "Now let's try to solve some questions:\n",
        "\n",
        "1. What if in $y=w\\times x+b$, the `w`, `x` and `b` are all 1-dimensional array? What about two-dimensional array? What will `w.grad` looks like?\n",
        "\n",
        "  * When the tensor is 1D tensor, there is no gradient ?\n",
        "\n",
        "2. What if we have the **chain role**, which means: $y = w\\times x + b$, $w = m\\times p + q$? What will happen if we want to calcualte `p.grad`?\n",
        "\n",
        "  * If you make sure that you have the leaf node, then the gradient is correct, but if not, then you need to use other settings, e.g. `retain_grad()` on the non-leaf tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFUa5H7nUrIv",
        "outputId": "b186112e-90d4-46ee-9ee6-bc99381c6992"
      },
      "source": [
        "# Problem 1 - tensor operation is by element\n",
        "x = torch.tensor([1.0, 2.0])\n",
        "w = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "b = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "y = w * x + b\n",
        "print(y)\n",
        "print('dy/dw:', w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 6.], grad_fn=<AddBackward0>)\n",
            "dy/dw: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyJlx5vVV5n8",
        "outputId": "18916772-d840-4a62-97a5-9933612704be"
      },
      "source": [
        "# Problem 2 - chain role \n",
        "x = torch.tensor(1.0)\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(5.0, requires_grad=True)\n",
        "\n",
        "c = w + b \n",
        "c.retain_grad() # since c is a non-leaf node, then you need to use \n",
        "y = c * w * x + b\n",
        "\n",
        "# calculate gradient\n",
        "y.backward()\n",
        "print('dy/dw: ', w.grad)\n",
        "print('dy/dc: ', c.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dw:  tensor(9.)\n",
            "dy/dc:  tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TzrHXY3Rd3c"
      },
      "source": [
        "## Interoperability with Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZhCEnllR6l2"
      },
      "source": [
        "If you want to change numpy array to tensor, you need to use `torch.from_numpy(array)`.\n",
        "\n",
        "Convert from pytorch tensor to numpy array: `y.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHq6TSAQmzE"
      },
      "source": [
        "# numpy is written in C++, which means this is very efficient\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUFOeD63RmCw",
        "outputId": "8075281f-882a-464a-c228-3858b13a803e"
      },
      "source": [
        "x = np.array([[1, 2],[3, 4]])\n",
        "y = torch.from_numpy(x)\n",
        "print(y, y.dtype)\n",
        "z = y.numpy()\n",
        "print(z, z.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) torch.int64\n",
            "[[1 2]\n",
            " [3 4]] int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ1PmuQIYKgi"
      },
      "source": [
        "# Linear Regression of PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpA-ShfjYUFC"
      },
      "source": [
        "Linear Regression means that we want to rationalize the data by using a linear model: $y = wx+b$. (w: weights, b: bias) We know all the $(x,y)$, now we want to find the optimal coefficient $(m,b)$. Notice that in here, `w` could be a matrix and `b` could also be a vector when `x` and `y` are vectors.\n",
        "\n",
        "This is a really simple assumption and usually it is the first step of our modeling process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaGxWNPwaQr9"
      },
      "source": [
        "Our first problem is to predict the yield of apple and orange by giving a certain temperature, rainfall and humidity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMZm1yUvf9C1"
      },
      "source": [
        "## Set inputs and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcATp1lSqzK"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPY5f6yxaos3"
      },
      "source": [
        "# Targets (yield_apples, yield_oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlMluBfa4ka"
      },
      "source": [
        "The reason why we seperate the input variables and target variables is because we need to treat them differently in our program. Also we've created numpy arrays, because this is typically how you would work with training data: read some CSV files as numpy arrays, do some processing, and then convert them to Pytorch tensors to do further training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnTLuX6jazeE"
      },
      "source": [
        "# convert numpy array for torch tensors\n",
        "inputs_torch = torch.from_numpy(inputs)\n",
        "targets_torch = torch.from_numpy(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-tqZKydbUf6",
        "outputId": "d9528d10-12a4-4cd8-979b-7749b7cb23c7"
      },
      "source": [
        "# start the value of weight and bias from a random value\n",
        "# since we have 2 targets and 3 inputs, then our weight should be a 2x3 matrix\n",
        "# our bias should have same size as our targets\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(1, 2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3066,  0.9426, -1.5872],\n",
            "        [-1.2522,  1.0184, -1.1143]], requires_grad=True)\n",
            "tensor([[0.3716, 0.0434]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InOucMrTcNiB"
      },
      "source": [
        "When our weight is a matrix, then our linear regression can be written as:\n",
        "$$y = x \\cdot w^T + b$$\n",
        "\n",
        "The size of our weight matrix is related to the number of features and the number of outputs.\n",
        "\n",
        "**Make sure that the dimension of your matrix is correct! Really important!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQQEfg0sgUd-"
      },
      "source": [
        "## Build our model\n",
        "\n",
        "In this case it is a linear regression model, but in the future, the model can be really complex (e.g. A neural network model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TTNWlHcbofF"
      },
      "source": [
        "# define the model\n",
        "def model(x):\n",
        "  return x @ w.t() + b # @ means matrix multiplication"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkyB357FctO_",
        "outputId": "655b935f-cbb0-4b7f-ebc3-8f81dc736deb"
      },
      "source": [
        "# predictions of our model \n",
        "preds = model(inputs_torch)\n",
        "print(preds) # really, really bad ... right now ..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[100.3761,  17.6190],\n",
            "        [133.1410,  10.2199],\n",
            "        [ 80.8693, -55.7864],\n",
            "        [156.0216, 105.1184],\n",
            "        [101.3740, -43.1640]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm61a70DdXEZ",
        "outputId": "e5dc2910-cadb-4f01-9ed1-10e8ffa8add1"
      },
      "source": [
        "print(targets_torch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvibYOtWgd9o"
      },
      "source": [
        "## Calculate the loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrWFiEpMfRLz"
      },
      "source": [
        "The **mean-square error** can be defined as:\n",
        "\n",
        "$$mse=\\frac{1}{N}\\sum_{i=1}^N(t_1^i-t_2^i)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXxoXuF9ee2z"
      },
      "source": [
        "# define the mean-square error\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff*diff)/diff.numel() # diff*diff: element-wise multiplication; diff.numel() number of elements in diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jAhXRlegps-"
      },
      "source": [
        "## Calculate the gradient --> Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K0Olkrjg2N7"
      },
      "source": [
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(1, 2, requires_grad=True)\n",
        "threshold = 10\n",
        "lr = 1e-5 # learning_rate\n",
        "ind = 0 #\n",
        "preds = model(inputs_torch)\n",
        "loss = mse(preds, targets_torch)\n",
        "print(loss)\n",
        "while loss > threshold:\n",
        "    new_preds = model(inputs_torch)\n",
        "    loss = mse(new_preds, targets_torch)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad\n",
        "        b -= lr * b.grad\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "    ind += 1\n",
        "    print('Epoch {} ... loss = {}'.format(ind, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjdbNE2bwrDn",
        "outputId": "78db523d-f6f9-49b5-90c3-078606f27ad1"
      },
      "source": [
        "preds = model(inputs_torch)\n",
        "print(preds)\n",
        "print(targets_torch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 58.2112,  69.5565],\n",
            "        [ 81.6339, 100.3739],\n",
            "        [118.3174, 134.8474],\n",
            "        [ 26.1825,  31.0243],\n",
            "        [ 98.1191, 122.4509]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86DqZcj8v-nf"
      },
      "source": [
        "In here I need to say: in pytorch, `a = a - 1` is not the same as `a -= 1`.\n",
        "\n",
        "* `a = a - 1` means first we evaluate `a-1`, then we create another tensor `a`, which has different reference number \n",
        "\n",
        "* `a -= 1` means we only evaluate `a-1`, but the reference for `a` is the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHp4QPwKtRlG",
        "outputId": "63eabb25-03c9-4a3b-cf9d-846599f4bfd0"
      },
      "source": [
        "a = torch.tensor([1, 2])\n",
        "print('original id = {}'.format(id(a)))\n",
        "b = torch.tensor([2, 2])\n",
        "a -= b\n",
        "print('After a = a - b, id = {}'.format(id(a)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original id = 139940533485432\n",
            "After a = a - b, id = 139940533485432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl3KGIFMx5AT"
      },
      "source": [
        "## Use pytorch built-in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mMzf5S3yVeb"
      },
      "source": [
        "import torch.nn as nn \n",
        "# nn means neural network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWEuui7ax4Ky"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNZF152btyOG"
      },
      "source": [
        "# dataset and dataloader (batching)\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# define our dataset \n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "\n",
        "# dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# define batch size \n",
        "batch_size = 10\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufkn4nQ0yyzV",
        "outputId": "b362add0-cf08-46fb-f26f-15a67cd25641"
      },
      "source": [
        "# look at 1 batch\n",
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 87., 134.,  58.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 73.,  66.,  44.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [103.,  43.,  36.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [ 68.,  96.,  71.],\n",
            "        [ 74.,  66.,  43.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[119., 133.],\n",
            "        [ 56.,  70.],\n",
            "        [ 57.,  69.],\n",
            "        [ 21.,  38.],\n",
            "        [ 80., 102.],\n",
            "        [ 20.,  38.],\n",
            "        [118., 134.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf_iaTAVzSBi",
        "outputId": "819e0627-0363-4a89-c1f8-06b5d5620bde"
      },
      "source": [
        "# define model\n",
        "model = nn.Linear(3, 2) # 3 is the number of your features, 2 is the number of your outputs\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0298,  0.4024, -0.1152],\n",
            "        [ 0.5231, -0.2843, -0.1735]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1466, 0.4071], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnN3msG6zouY",
        "outputId": "13b35dc9-d295-4873-850c-028cd9542ce2"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0298,  0.4024, -0.1152],\n",
              "         [ 0.5231, -0.2843, -0.1735]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1466, 0.4071], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf4IrLNszs1H",
        "outputId": "40a8a6cf-80e6-4bf8-9266-b640efe205d4"
      },
      "source": [
        "# make predictions\n",
        "preds = model(inputs_torch)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[19.9765, 12.0850],\n",
            "        [25.4707, 11.8874],\n",
            "        [44.7912, -2.2405],\n",
            "        [10.1458, 35.1170],\n",
            "        [28.6545, -2.9349]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33klDScoz3pA",
        "outputId": "b9fd4d48-6e47-4b80-ac67-cb840b92e425"
      },
      "source": [
        "# define loss function \n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_fn = F.mse_loss\n",
        "\n",
        "loss = loss_fn(model(inputs_torch), targets_torch)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6001.2764, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN4358eD0YqZ"
      },
      "source": [
        "# define optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5) # lr means learning-rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfUBSI5Z0mpN"
      },
      "source": [
        "# train the model\n",
        "# utility function to train the model \n",
        "def fit(num_epochs, train_dl, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb, yb in train_dl:\n",
        "            # 1. Generate prediction\n",
        "            preds = model(xb)\n",
        "\n",
        "            # 2. Calculate the loss \n",
        "            loss = loss_fn(preds, yb)\n",
        "\n",
        "            # 3. Compute gradients \n",
        "            loss.backward()\n",
        "\n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "\n",
        "            # 5. Reset the gradients to zero \n",
        "            opt.zero_grad() \n",
        "\n",
        "        if (epoch+1)%10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss))\n",
        "             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnrG4wQU1lEq",
        "outputId": "44279dd6-f7d6-4f43-bc34-98b303ea503a"
      },
      "source": [
        "fit(100, train_dl, model, loss_fn, opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 42.0496\n",
            "Epoch [20/100], Loss: 44.0107\n",
            "Epoch [30/100], Loss: 80.4472\n",
            "Epoch [40/100], Loss: 71.6844\n",
            "Epoch [50/100], Loss: 45.9663\n",
            "Epoch [60/100], Loss: 40.9093\n",
            "Epoch [70/100], Loss: 49.8164\n",
            "Epoch [80/100], Loss: 39.4097\n",
            "Epoch [90/100], Loss: 34.3259\n",
            "Epoch [100/100], Loss: 18.9639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYxaRa1K1pzX",
        "outputId": "7ae7649b-c5d8-431b-f912-eeb6051918f4"
      },
      "source": [
        "preds = model(inputs)\n",
        "print(preds)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 57.6456,  71.5131],\n",
            "        [ 79.2267,  97.5071],\n",
            "        [123.2662, 137.0268],\n",
            "        [ 24.5356,  44.1636],\n",
            "        [ 94.8529, 109.6299],\n",
            "        [ 56.3971,  70.5016],\n",
            "        [ 78.5486,  97.0258],\n",
            "        [123.2827, 137.3443],\n",
            "        [ 25.7841,  45.1751],\n",
            "        [ 95.4234, 110.1600],\n",
            "        [ 56.9675,  71.0317],\n",
            "        [ 77.9782,  96.4957],\n",
            "        [123.9443, 137.5082],\n",
            "        [ 23.9652,  43.6335],\n",
            "        [ 96.1015, 110.6414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0VGN5gI2kew"
      },
      "source": [
        "## Summary\n",
        "\n",
        "So in order to make a machine learning model, we need:\n",
        "\n",
        "* Number of Epochs\n",
        "* Training Data (features + targets)\n",
        "* Testing Data\n",
        "* Model\n",
        "* Loss function\n",
        "* Optimizer\n",
        "\n",
        "In this example, we can put each statement in the following:\n",
        "\n",
        "* Number of Epochs\n",
        "    ``` python\n",
        "    num_epochs = 100\n",
        "    ```\n",
        "* Training Data (features + targets)\n",
        "    ``` python\n",
        "    # Input (temp, rainfall, humidity)\n",
        "    inputs = np.array([[73, 67, 43], \n",
        "                    [91, 88, 64], \n",
        "                    [87, 134, 58], \n",
        "                    [102, 43, 37], \n",
        "                    [69, 96, 70], \n",
        "                    [74, 66, 43], \n",
        "                    [91, 87, 65], \n",
        "                    [88, 134, 59], \n",
        "                    [101, 44, 37], \n",
        "                    [68, 96, 71], \n",
        "                    [73, 66, 44], \n",
        "                    [92, 87, 64], \n",
        "                    [87, 135, 57], \n",
        "                    [103, 43, 36], \n",
        "                    [68, 97, 70]], \n",
        "                    dtype='float32')\n",
        "\n",
        "    # Targets (apples, oranges)\n",
        "    targets = np.array([[56, 70], \n",
        "                        [81, 101], \n",
        "                        [119, 133], \n",
        "                        [22, 37], \n",
        "                        [103, 119],\n",
        "                        [57, 69], \n",
        "                        [80, 102], \n",
        "                        [118, 132], \n",
        "                        [21, 38], \n",
        "                        [104, 118], \n",
        "                        [57, 69], \n",
        "                        [82, 100], \n",
        "                        [118, 134], \n",
        "                        [20, 38], \n",
        "                        [102, 120]], \n",
        "                    dtype='float32')\n",
        "\n",
        "    inputs = torch.from_numpy(inputs)\n",
        "    targets = torch.from_numpy(targets)\n",
        "\n",
        "    # dataset and dataloader (batching)\n",
        "\n",
        "    from torch.utils.data import TensorDataset\n",
        "\n",
        "    # define our dataset \n",
        "    train_ds = TensorDataset(inputs, targets)\n",
        "\n",
        "    # dataloader\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    # define batch size \n",
        "    batch_size = 10\n",
        "    train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "    ```\n",
        "* Testing Data\n",
        "* Model\n",
        "\n",
        "    ``` python\n",
        "    import torch.nn as nn\n",
        "    # define model\n",
        "    model = nn.Linear(3, 2) # 3 is the number of your features, 2 is the number of your outputs\n",
        "    print(model.weight)\n",
        "    print(model.bias)\n",
        "    ```\n",
        "* Loss function\n",
        "\n",
        "    ``` python\n",
        "    # define loss function \n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    loss_fn = F.mse_loss\n",
        "\n",
        "    loss = loss_fn(model(inputs_torch), targets_torch)\n",
        "    ```\n",
        "\n",
        "* Optimizer\n",
        "    ``` python\n",
        "    # define optimizer\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=1e-5) # lr means learning-rate\n",
        "    ```\n",
        "\n",
        "We can write a general training model `fit()`:\n",
        "\n",
        "``` python\n",
        "# train the model\n",
        "# utility function to train the model \n",
        "def fit(num_epochs, train_dl, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb, yb in train_dl:\n",
        "            # 1. Generate prediction\n",
        "            preds = model(xb)\n",
        "\n",
        "            # 2. Calculate the loss \n",
        "            loss = loss_fn(preds, yb)\n",
        "\n",
        "            # 3. Compute gradients \n",
        "            loss.backward()\n",
        "\n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "\n",
        "            # 5. Reset the gradients to zero \n",
        "            opt.zero_grad() \n",
        "\n",
        "        if (epoch+1)%10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss))\n",
        "```\n",
        "\n",
        "Once we have the `num_epochs`, `train_dl`, `model`, `loss_fn` and `opt`, then we can start training out machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAnKS6l2RiI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvqEii4RMP2A"
      },
      "source": [
        "# Image Classification and logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQcFtI59MUKd"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "13eabfacef7f4472ab72a1867d760829",
            "98d526ad8cac4592af6824f55ae76a28",
            "a90271fb4e2e4f44995b0bfd49be56d1",
            "860da238b2e84a0fa09c6905d453c89a",
            "bf8bb4259d0341d1a0a3a209f1773080",
            "917b17c9d11445c1ab916142c5a0621a",
            "bba5431464184751a4a009d90d70ab4c",
            "a251c2daa3af4172ac7931beaa65452f",
            "e97ac7b2bb694f4997bebb92ddf37dd6",
            "456477b388094258b56c8ecef3ddefec",
            "7a9e38bd200f4a0ab76c2bd8c1e3f0f2",
            "ca07778e5d5645588e7d6e42de6b2e6b",
            "a47cf0dffdf94706a902be093fc5bab0",
            "bbd25e5db02e46e09260fd0851c8709d",
            "ae6f17392a9548c2a082d4392ccfae15",
            "c9ffb1d7ee33408283ff9041b9da48f9",
            "199b414d84a54ff0a78ba98e52236c37",
            "5b370630541f4ebc94baebd797deeff7",
            "42fb6fd0147f4aa49d2610a6b73f1c2f",
            "200b67cb9de6430280487a5a47f9ec4d",
            "342b599c20ad404da4a33bd6c3b1fa72",
            "9427f74c92fb46d7a790ac71064b01eb",
            "c40e9bc396df49d79e71c779532c7d87",
            "ebe8a51e57774d70a2cbe56041f202df",
            "e1e3b4669da446e28f5bd8273d7b395b",
            "cfaa9223770c4382854ea2f529705071",
            "3e4ca7e78a9e411b88aae61d5468c98c",
            "a15417c450b2400b8a360c48b2f58f7e",
            "e62772c132504383b93236c67d350de2",
            "4bf29cbf56cb4974bf171d463c37bd37",
            "9506ac17d4ea4b7ea72028a149663d9c",
            "3368b7a7476e4993ad4caacbeeebbb3d"
          ]
        },
        "id": "-TukuD79NEvA",
        "outputId": "9611ff49-cb93-4f94-8216-ff5c4c945d43"
      },
      "source": [
        "# Download training dataset\n",
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13eabfacef7f4472ab72a1867d760829",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97ac7b2bb694f4997bebb92ddf37dd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "199b414d84a54ff0a78ba98e52236c37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1e3b4669da446e28f5bd8273d7b395b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hN_1OqZNNLr",
        "outputId": "f9023bff-e8cd-4784-90c7-6f7d8f76eadf"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t2-Re4ZNU88",
        "outputId": "321a8f6d-5b71-42c3-8a61-a63fb9a9d493"
      },
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL40pcfGNcmD",
        "outputId": "129d9437-bec8-4da1-d47c-4cd0b0669713"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F307C07B7B8>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSmmfTmVNexc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "OUiVETu2NlDE",
        "outputId": "278f7c1d-a95d-43c3-c948-bfca31c387d6"
      },
      "source": [
        "image, label = dataset[10]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmG5b2b_OIDm"
      },
      "source": [
        "# transform the MNIST figure to a tensor\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMnNTzcAPQfc"
      },
      "source": [
        "dataset = MNIST(root='data/', train=True, transform=transforms.ToTensor())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl8AlheOPYdb",
        "outputId": "45f24752-3765-451d-a435-3abc463c9ac9"
      },
      "source": [
        "img_tensor, label = dataset[0] \n",
        "print(img_tensor.shape, label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STEhgHFiPguk",
        "outputId": "d40a91d8-2cf9-4414-aa47-5292922e1304"
      },
      "source": [
        "print(img_tensor[:, 10:15, 10:15])\n",
        "print(torch.max(img_tensor), torch.min(img_tensor))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
            "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
            "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
            "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
            "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
            "tensor(1.) tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mVnudde5PpHd",
        "outputId": "11b7c0ac-3ed1-4141-a2b8-1ea2a6e6ad3b"
      },
      "source": [
        "plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f30849f1160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26VjBUZrPzAO"
      },
      "source": [
        "# split the dataset into three parts: (1) training set (2) test set (3) validation set\n",
        "import numpy as np\n",
        "\n",
        "def split_indices(n, val_pct):\n",
        "    n_val = int(val_pct*n)\n",
        "    idxs = np.random.permutation(n)\n",
        "    return idxs[n_val:], idxs[:n_val] "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKLbGl5HRGmW",
        "outputId": "6660b503-8807-4f34-fccf-8dc1ab63d513"
      },
      "source": [
        "train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)\n",
        "print(len(train_indices), len(val_indices))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEbKTXzcRcX8"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xuppO8QRpnU"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "# training sampler and data loader\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "train_loader = DataLoader(dataset, batch_size, sampler=train_sampler)\n",
        "\n",
        "# validation sampler \n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "val_loader = DataLoader(dataset, batch_size, sampler=val_sampler)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx13Qy5MSMLw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}